{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled18.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "soYDELwpR6iR"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jlz8v0dVbJxo"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#픽셀 평준화\n",
        "train_scaled = train_input / 255.0\n",
        "train_scaled = train_scaled.reshape(-1, 28*28)\n",
        "\n",
        "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
        "    train_scaled, train_target, test_size=0.2)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg3Tb0TvbZZH"
      },
      "source": [
        "# **심층 신경망**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltt5QWk1bOtV",
        "outputId": "47431810-68c8-4ecf-fc28-eac0e3ad8722"
      },
      "source": [
        "#시그모이드 함수 사용층\n",
        "dense1 = keras.layers.Dense(100, activation='sigmoid', input_shape=(784,),name='hidden')\n",
        "#소프트맥스 함수 사용층\n",
        "dense2 = keras.layers.Dense(10, activation='softmax',name='output')\n",
        "#입력층 -> dense1(은닉층) -> dense2(출력층)\n",
        "model = keras.Sequential([dense1, dense2])\n",
        "model.summary()\n",
        "#Layer(type):레이어 이름과 타입\n",
        "#Output Shape:출력 배열의 형태. None은 나중에 지정 가능하다는 의미이다.\n",
        "#Param:각 층의 가중치와 절편의 총 개수\n",
        "#은닉층(hidden)의 경우 입력층의 출력이 784개이고 100개의 뉴런이 있으므로 784*100(가중치 개수)+100(각 뉴런마다 한개의 절편)으로 Param값은 78500\n",
        "#출력층(output)의 경우 은닉층의 출력이 100개이고 10개의 뉴런이 있으므로 100*10(가중치 개수)+10(각 뉴런마다 한개의 절편)으로 Param값은 1010"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "hidden (Dense)               (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD-iol_-eLSk"
      },
      "source": [
        "**층을 추가하는 다른 방법**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjIxluBYeOwY",
        "outputId": "079efde4-d0b7-4c93-da2f-f1ff900cdcae"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(100, activation='sigmoid', input_shape=(784,), name='hidden'),\n",
        "    keras.layers.Dense(10, activation='softmax', name='output')\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "hidden (Dense)               (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE2mUyCQesMx",
        "outputId": "8ec65359-eb13-4915-e016-9a3507113bd8"
      },
      "source": [
        "#권장\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(100, activation='sigmoid', input_shape=(784,),name='hidden'))\n",
        "model.add(keras.layers.Dense(10, activation='softmax',name='output'))\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "hidden (Dense)               (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-Tb1FRQfH6c",
        "outputId": "01eed927-904a-4558-b2fe-473d21468bce"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "\n",
        "model.fit(train_scaled, train_target, epochs=5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 6s 2ms/step - loss: 0.7738 - accuracy: 0.7538\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4187 - accuracy: 0.8512\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3739 - accuracy: 0.8654\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3458 - accuracy: 0.8752\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3348 - accuracy: 0.8809\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f24a81a97d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6wxOY4Agro6"
      },
      "source": [
        "**렐루 활성함수와 Flatten층**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIVgEsSego8I",
        "outputId": "5bd02235-e389-4be3-d5c3-ded2db2f51c6"
      },
      "source": [
        "model = keras.Sequential()\n",
        "#Flatten층:편의를 위한 층으로 입력으로 받은 다차원 배열을 1차원 배열로 펼쳐준다.\n",
        "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "#렐루(relu) 활성함수는 시그모이드함수보다 학습을 더 빠르고 효율적으로 할 수 있게 도와준다.\n",
        "model.add(keras.layers.Dense(100, activation='relu',name='hidden'))\n",
        "model.add(keras.layers.Dense(10, activation='softmax',name='output'))\n",
        "model.summary()\n",
        "#아래를 보면 Flatten층은 파라미터가 0개이고 출력으로 784(28*28)개의 1차원 배열임을 알 수 있다."
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_3 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niaif0s5iL6_",
        "outputId": "26c8bf13-7635-480a-8653-285b099cc53a"
      },
      "source": [
        "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "train_scaled = train_input / 255.0\n",
        "\n",
        "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
        "    train_scaled, train_target, test_size=0.2,)\n",
        "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "\n",
        "model.fit(train_scaled, train_target, epochs=5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.6841 - accuracy: 0.7638\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4074 - accuracy: 0.8551\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3569 - accuracy: 0.8728\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3408 - accuracy: 0.8780\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3295 - accuracy: 0.8824\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2491751ed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjADR-SliATm",
        "outputId": "484b188b-730f-4194-f8e1-fca50d2aec99"
      },
      "source": [
        "model.evaluate(val_scaled, val_target)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3539 - accuracy: 0.8788\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3539038896560669, 0.8788333535194397]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_02mzE4h6yc"
      },
      "source": [
        "# **옵티마이저**\n",
        "*optimizer매개변수는 모델의 최적화 방법을 설정할 수 있다.(기본값:'sgd')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu4OutJ0k3QG"
      },
      "source": [
        "#모델 초기화 함수\n",
        "def init_model():\n",
        "  model = keras.Sequential()  \n",
        "  model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "  model.add(keras.layers.Dense(100, activation='relu',name='hidden'))\n",
        "  model.add(keras.layers.Dense(10, activation='softmax',name='output'))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uORK2Jmh6M1"
      },
      "source": [
        "#sgd:확률적 경사 하강법('확률적경사하강법' 참고)\n",
        "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "\n",
        "sgd = keras.optimizers.SGD()\n",
        "model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "#learning_rate:학습률(기본값:0.01)\n",
        "sgd = keras.optimizers.SGD(learning_rate=0.1)\n",
        "#momentum:모멘텀 방식 사용률(기본값:0)\n",
        "#nesterov:네스테로프 모멘텀 방식 사용 여부(기본값:False)\n",
        "sgd = keras.optimizers.SGD(momentum=0.9, nesterov=True)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tSsNZhMj7Sn"
      },
      "source": [
        "**적응형 학습률 옵티마이저**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5L_KCoHj6me"
      },
      "source": [
        "init_model()\n",
        "#Adagrad\n",
        "adagrad = keras.optimizers.Adagrad()\n",
        "model.compile(optimizer=adagrad, loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "init_model()\n",
        "#RMSprop\n",
        "rmsprop = keras.optimizers.RMSprop()\n",
        "model.compile(optimizer=rmsprop, loss='sparse_categorical_crossentropy', metrics='accuracy')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2Zy6zXokuYT",
        "outputId": "382fec28-a221-485b-ac17-9336d5b72712"
      },
      "source": [
        "init_model()\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "model.fit(train_scaled, train_target, epochs=5)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3055 - accuracy: 0.8903\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2887 - accuracy: 0.8939\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2667 - accuracy: 0.9004\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2594 - accuracy: 0.9027\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2432 - accuracy: 0.9087\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f24905e7e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bocf_3UllVi_",
        "outputId": "10f0c46b-a8b0-4f63-932a-fe43fd6e3069"
      },
      "source": [
        "model.evaluate(val_scaled, val_target)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3215 - accuracy: 0.8854\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.32152169942855835, 0.8854166865348816]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5riVZdkQloNP"
      },
      "source": [
        "# **앙상블 모델과 인공신경망 모델의 차이점**\n",
        "\n",
        "앙상블 모델과 인공신경망 모델은 여러개의 트리모델/뉴런을 사용하여 출력값을 낸다는 점에서 비슷하다고 볼 수 있다. 하지만 앙상블 모델은 여러개의 트리모델이 독립적으로 학습되는 데 반해, 인공신경망 모델은 모든 뉴런(밀집층의 경우)이 같이 학습되며, 앙상블모델과는 다르게 여러개의 층을 쌓을 수 있다는 장점이 있다.\n",
        " 이러한 차이점 때문에 앙상블 모델은 DB나 엑셀과 같은 정형화된 데이터 학습에 효과적이며, 인공신경망 모델은 이미지등의 비정형화된 데이터 학습에 효과적이다."
      ]
    }
  ]
}